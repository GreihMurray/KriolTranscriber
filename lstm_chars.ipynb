{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreihMurray/KriolTranscriber/blob/master/lstm_chars.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4H4aOYQJdg_",
        "outputId": "7714c5c4-9235-45b5-c76f-0c5dc0a22cfe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.7.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jiwer\n",
            "  Using cached jiwer-2.5.1-py3-none-any.whl (15 kB)\n",
            "Collecting levenshtein==0.20.2\n",
            "  Downloading Levenshtein-0.20.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 13.8 MB/s \n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 38.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, levenshtein, jiwer\n",
            "Successfully installed jiwer-2.5.1 levenshtein-0.20.2 rapidfuzz-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tiEm2CJT-ufY"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import activations\n",
        "import numpy as np\n",
        "from evaluate import load\n",
        "import itertools\n",
        "from scipy.io import wavfile\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Reshape, GRU, Flatten, Activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5Yl8pSEy8_hu"
      },
      "outputs": [],
      "source": [
        "import math, random\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio import transforms\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import unicodedata\n",
        "import re\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzyMxwpr9E2o",
        "outputId": "26075b03-135e-4886-bfc6-99b39c0bf5ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "u-KbCzwD9F7D"
      },
      "outputs": [],
      "source": [
        "DEFAULT_DIR = '/content/gdrive/MyDrive/Colab_Notebooks/NLP/project/'\n",
        "SR = 44100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ujj8a26e9HOp"
      },
      "outputs": [],
      "source": [
        "def load_html_data(dir_ext):\n",
        "    all_data = []\n",
        "    chars_to_replace = '.,;:<>?/\\'\\\\[]()!#$%\"”“'\n",
        "    directory = DEFAULT_DIR + 'html/' + dir_ext + '/'\n",
        "\n",
        "    dir_files = sorted(os.listdir(directory))\n",
        "\n",
        "    for file in tqdm(dir_files, desc='Loading HTML Data'):\n",
        "        file = directory + file\n",
        "        divs = []\n",
        "        with open(file, 'r', encoding='UTF-8') as in_file:\n",
        "            data = ' '.join(in_file.readlines())\n",
        "            data = unicodedata.normalize('NFC', data)\n",
        "            data = re.sub(r'<span class=.*?</span>', '', data)\n",
        "            data = re.sub(r'<a.*?</a>', '', data)\n",
        "            data = data.replace(u'\\xa0', u' ')\n",
        "            check_divs = re.findall(r'<div class=\\'mt\\'.*?>(.*?) </div>', data)\n",
        "            check_divs.extend(re.findall(r'<div class=\\'mt2\\'.*?>(.*?) </div>', data))\n",
        "            # print(data)\n",
        "            check_divs.extend(re.findall(r'<div class=\\'ip\\'>(.*)', data))\n",
        "\n",
        "            if len(check_divs) > 0:\n",
        "                full = '!'.join(check_divs)\n",
        "                full = re.sub(r'[\\,,@,#,$,%,^,&,*,(,),\\[,\\],\\',\\\",;,:,“,”,‘,’]', '', full)\n",
        "                full = re.sub('^\\s+', ' ', full).strip('\\u00A0')\n",
        "                full = re.split('[\\.,\\?,!,\\n]', str(full))\n",
        "                all_data.extend([s.strip() for s in full])\n",
        "\n",
        "            divs.extend(re.findall(r'<div class=\\'[p,s]\\'.*?>(.*?) </div>', data))\n",
        "\n",
        "        full_data = '!'.join(divs)\n",
        "        full_data = re.sub(r'[\\,,@,#,$,%,^,&,*,(,),\\[,\\],\\',\\\",;,:,“,”,‘,’]', '', full_data)\n",
        "        full_data = re.sub(' +', ' ', full_data)\n",
        "        full_data = re.split('[\\.,\\?,!,\\n]', str(full_data))\n",
        "\n",
        "        all_data.extend([s.strip() for s in full_data])\n",
        "\n",
        "        clean = []\n",
        "        for row2 in all_data:\n",
        "            if len(row2) >= 1:\n",
        "                clean.append(row2.lower())\n",
        "\n",
        "    return clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WxujUpiQ9IjU"
      },
      "outputs": [],
      "source": [
        "def load_dataset(dir_ext):\n",
        "    transcripts = load_html_data(dir_ext)\n",
        "    all_x = []\n",
        "    all_y = []\n",
        "    directory = DEFAULT_DIR + 'audio/' + dir_ext + '/'\n",
        "\n",
        "    order = []\n",
        "\n",
        "    dir_files = sorted(os.listdir(directory))\n",
        "\n",
        "    for i, file in tqdm(enumerate(dir_files), desc='Loading Audio Data & Creating Dataset'):\n",
        "        file = directory + file\n",
        "        \n",
        "        sr, data = wavfile.read(file)\n",
        "\n",
        "        max_len = SR//1000 * 15000\n",
        "\n",
        "        if len(data) > max_len:\n",
        "          continue\n",
        "\n",
        "        all_x.append(data)\n",
        "        all_y.append(transcripts[i])\n",
        "\n",
        "\n",
        "    return pd.DataFrame(list(zip(all_x, all_y)), columns=['audio', 'transcription'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FQb1aO129R-t"
      },
      "outputs": [],
      "source": [
        "def one_hot(data, test_data, map_use):\n",
        "    mapping = {}\n",
        "    mapped = []\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    if not test_data:\n",
        "        for sentence in data:\n",
        "          cur_map = []\n",
        "          for word in sentence:\n",
        "              if word in mapping.keys():\n",
        "                cur_map.append(mapping[word])\n",
        "              else:\n",
        "                i += 1\n",
        "                cur_map.append(i)\n",
        "                mapping[word] = i\n",
        "                \n",
        "          mapped.append(cur_map)\n",
        "    else:\n",
        "        for sentence in data:\n",
        "          cur_map = []\n",
        "          for word in sentence:\n",
        "              if word in map_use.keys():\n",
        "                cur_map.append(map_use[word])\n",
        "              else:\n",
        "                i += 1\n",
        "                cur_map.append(i)\n",
        "                map_use[word] = i\n",
        "                \n",
        "          mapped.append(cur_map)\n",
        "      \n",
        "    return mapped, mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "w1aYZcfH9TDQ"
      },
      "outputs": [],
      "source": [
        "def vectorize(data):\n",
        "    vecs = []\n",
        "    for row in data:\n",
        "      cur_vec = [0] * len(row[0])\n",
        "      for piece in row:\n",
        "        piece = list(piece)\n",
        "        cur_vec[piece.index(1)] += 1\n",
        "      cur_vec[2] = 1\n",
        "      vecs.append(cur_vec)\n",
        "\n",
        "    return vecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oYBr-R5393cs"
      },
      "outputs": [],
      "source": [
        "def pad_audio(data):\n",
        "    max_len = SR//1000 * 15000\n",
        "\n",
        "    for i, aud in tqdm(enumerate(data), desc='Padding audio'):\n",
        "      if len(aud) < max_len:\n",
        "        data[i] = np.array(np.append(aud, np.zeros(max_len - len(aud))))\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "93m3kZVEB20q"
      },
      "outputs": [],
      "source": [
        "def get_min(audio):\n",
        "    minim = 0\n",
        "\n",
        "    for row in tqdm(audio, desc='Finding min'):\n",
        "        if min(row) < minim:\n",
        "            minim = min(row)\n",
        "    \n",
        "    return minim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "X2wjJymUDatt"
      },
      "outputs": [],
      "source": [
        "def get_max(audio):\n",
        "    maxim = 0\n",
        "\n",
        "    for row in tqdm(audio, desc='Finding max'):\n",
        "        if max(row) > maxim:\n",
        "           maxim = max(row)\n",
        "\n",
        "    return maxim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QqsHwHwlCRAG"
      },
      "outputs": [],
      "source": [
        "def adjust_audio(audio, minim):\n",
        "    for i, row in tqdm(enumerate(audio), desc='Adjusting Audio'):\n",
        "        for j, val in enumerate(row):\n",
        "            audio[i][j] = int(val + abs(minim))\n",
        "\n",
        "    return audio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def advanced_relu(x):\n",
        "    return K.relu(x, max_value=500000)"
      ],
      "metadata": {
        "id": "JH4lOO_JtToL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XDzD3p6QBLV-"
      },
      "outputs": [],
      "source": [
        "def build_model(input_len, output_len, maxim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(321, input_shape=(input_len,), activation=advanced_relu))\n",
        "    model.add(Embedding(input_dim=499999, output_dim=34))\n",
        "    model.add(Bidirectional(LSTM(units=50, return_sequences=True, recurrent_dropout=0.1)))\n",
        "    model.add(Dense(34, activation='softmax'))\n",
        "    #model.add(Reshape((321, 34)))\n",
        "    \n",
        "    model.compile(optimizer=\"adam\", metrics=[\"accuracy\"], loss='categorical_crossentropy')\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_data(folder_path, test_data=False, map_use=None):\n",
        "    df = load_dataset(folder_path)\n",
        "    clean_y = list(df['transcription'])\n",
        "\n",
        "    padded_y = list(zip(*itertools.zip_longest(*list(df['transcription']), fillvalue='!')))\n",
        "    enc_y, mapping = one_hot(padded_y, test_data, map_use)\n",
        "    cat_y = np.array(to_categorical(enc_y))\n",
        "\n",
        "    padded_x = pad_audio(df['audio'])\n",
        "\n",
        "    minim = get_min(padded_x)\n",
        "    padded_x = adjust_audio(padded_x, minim)\n",
        "    maxim = get_max(padded_x)\n",
        "\n",
        "    padded_x = np.stack(padded_x)\n",
        "\n",
        "    for entry in cat_y:\n",
        "        for row in entry:\n",
        "            if row[7] != 0:\n",
        "                row[7] = 0\n",
        "\n",
        "    return clean_y, cat_y, padded_x, minim, maxim, mapping"
      ],
      "metadata": {
        "id": "OHe43qhnHN5a"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, clean_y, padded_x, mapping):\n",
        "    cur_words = []\n",
        "\n",
        "    map_list = mapping.items()\n",
        "    map_key = list(mapping.keys())\n",
        "\n",
        "    last_char = False\n",
        "\n",
        "    all_words = []\n",
        "\n",
        "    preds = model.predict(padded_x)\n",
        "\n",
        "    print(len(preds))\n",
        "\n",
        "    for pred in preds:\n",
        "        cur_words = []\n",
        "        for row in pred:\n",
        "            row = list(row)\n",
        "            cur_words.append(map_key[row.index(max(row))-1])\n",
        "            \n",
        "        len_words = len(cur_words) - 1\n",
        "\n",
        "        for i in range(len_words, 0, -1):\n",
        "            if cur_words[i] != ' ':\n",
        "                joined = ''.join(cur_words)\n",
        "                all_words.append(re.sub(' +', ' ', joined))\n",
        "                break\n",
        "            else:\n",
        "                cur_words.pop()\n",
        "\n",
        "    cer = load('cer')\n",
        "    cer_score = cer.compute(predictions=all_words, references=clean_y)\n",
        "    print('Character Error Rate:', cer_score)\n",
        "\n",
        "    wer = load('wer')\n",
        "    wer_score = wer.compute(predictions=all_words, references=clean_y)\n",
        "    print('Word Error Rate:', wer_score)"
      ],
      "metadata": {
        "id": "fPKbFnrcIlDM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(train=False, model=''):\n",
        "    print('\\033[95m' + 'LOADING TRAINING DATA\\n')\n",
        "    clean_y, cat_y, padded_x, minim, maxim, mapping = load_and_process_data('train')\n",
        "    print('\\n\\n', '\\033[95m' + 'LOADING TESTING DATA\\n', sep='')\n",
        "    y_test, _, x_test, _, _, _ = load_and_process_data('train', test_data=True, map_use=mapping)\n",
        "\n",
        "    if train:\n",
        "        model = build_model(len(padded_x[0]), len(cat_y[0]), maxim)\n",
        "        plot_model(model, show_shapes=True)\n",
        "\n",
        "        model.fit(padded_x, cat_y, epochs=100, verbose=1, batch_size=1)\n",
        "    else:\n",
        "        # '/content/gdrive/MyDrive/Colab_Notebooks/NLP/project/lstm_model_450e'\n",
        "        model = load_model(model)\n",
        "\n",
        "    evaluate(model, y_test, x_test, mapping)"
      ],
      "metadata": {
        "id": "WNrHFG7KHt71"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(model='/content/gdrive/MyDrive/Colab_Notebooks/NLP/project/lstm_model_450e')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "oG2yzsQ-J1y-",
        "outputId": "889cf0bd-500d-4293-d1d2-405ae2a68867"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[95mLOADING TRAINING DATA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading HTML Data: 100%|██████████| 293/293 [00:01<00:00, 168.88it/s]\n",
            "Loading Audio Data & Creating Dataset: 0it [00:00, ?it/s]<ipython-input-20-4cb6f964ff81>:14: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
            "  sr, data = wavfile.read(file)\n",
            "Loading Audio Data & Creating Dataset: 302it [00:00, 398.91it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-fa18784c777f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/Colab_Notebooks/NLP/project/lstm_model_450e'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-6d40500fd1e7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(train, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\033[95m'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'LOADING TRAINING DATA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mclean_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LOADING TESTING DATA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_use\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-36c11bfd6095>\u001b[0m in \u001b[0;36mload_and_process_data\u001b[0;34m(folder_path, test_data, map_use)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_and_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_use\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mclean_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transcription'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpadded_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip_longest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transcription'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-4cb6f964ff81>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(dir_ext)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSR\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m15000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/io/wavfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(filename, mmap)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mmmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPx/Nm5Ncprl3Jah4hRJPmC",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}